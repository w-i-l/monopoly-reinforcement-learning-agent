@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {1097--1105},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@misc{chatgpt,
  author = {OpenAI},
  title = {{Introducing ChatGPT}},
  howpublished = "\url{https://openai.com/index/chatgpt/}",
  year = {2022}, 
  note = "[Online; accesat 15-Mai-2025]"
}

@misc{sunoai,
  author    = {Suhailudheen P M and Ms Sheena Km},
  title     = {Suno AI: Advancing AI-Generated Music with Deep Learning},
  journal   = {TechRxiv},
  year      = {2025},
  month     = {4},
  day       = {9},
  url       = {https://www.techrxiv.org/users/909039/articles/1282999-suno-ai-advancing-ai-generated-music-with-deep-learning},
  note      = "[Online; accesat 20-Mai-2025]"
}

@misc{atari,
      title={Playing Atari with Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
      year={2013},
      eprint={1312.5602},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1312.5602}
}

@misc{rl_in_video_games,
  author    = {Zhengyang Li and Qijin Ji and Xinghong Ling and others},
  title     = {A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games},
  journal   = {TechRxiv},
  year      = {2025},
  month     = {1},
  day       = {4},
  doi       = {10.36227/techrxiv.173603149.94954703/v1}
}

@misc{wikipedia_monopoly,
  title     = {Monopoly},
  author    = {{Wikipedia}},
  url       = {https://ro.wikipedia.org/wiki/Monopoly},
  note      = "[Online; accesat 10-Mai-2025]",
  language  = {romanian}
}

@book{reinforcement_learning_book,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

@Inbook{markov_decision_process,
author="Uther, William",
editor="Sammut, Claude
and Webb, Geoffrey I.",
title="Markov Decision Processes",
bookTitle="Encyclopedia of Machine Learning",
year="2010",
publisher="Springer US",
address="Boston, MA",
pages="642--646",
isbn="978-0-387-30164-8",
doi="10.1007/978-0-387-30164-8_512",
url="https://doi.org/10.1007/978-0-387-30164-8_512"
}

@misc{reinforcement_learning_scheme_image,
  author    = {AltexSoft Editorial Team},
  title     = {Reinforcement Learning Explained: Overview, Comparisons and Applications in Business},
  url       = "https://www.altexsoft.com/blog/reinforcement-learning-explained-overview-comparisons-and-applications-in-business/",
  year      = {2019},
  month     = {1},
  day       = {21},
  note      = "[Online; accesat 12-Mai-2025]"
}

@article{mdp_monopoly_1,
  author    = {R. B. Ash and R. L. Bishop},
  title     = {Monopoly as a Markov Process},
  journal   = {Mathematics Magazine},
  volume    = {45},
  number    = {1},
  pages     = {26--29},
  year      = {1972}
}

@inproceedings{mdp_monopoly_2,
  author    = {P. Bailis and A. Fachantidis and I. Vlahavas},
  title     = {Learning to Play Monopoly: A Reinforcement Learning Approach},
  booktitle = {Proceedings of the 50th Anniversary Convention of The Society for the Study of Artificial Intelligence and Simulation of Behaviour},
  publisher = {AISB},
  year      = {2014}
}

@inproceedings{mdp_monopoly_3,
  author    = {E. Arun and H. Rajesh and D. Chakrabarti and H. Cherala and K. George},
  title     = {Monopoly Using Reinforcement Learning},
  booktitle = {TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)},
  year      = {2019},
  pages     = {858--862}
}

@misc{hybrid_monopoly,
      title={Decision Making in Monopoly using a Hybrid Deep Reinforcement Learning Approach}, 
      author={Trevor Bonjour and Marina Haliem and Aala Alsalem and Shilpa Thomas and Hongyu Li and Vaneet Aggarwal and Mayank Kejriwal and Bharat Bhargava},
      year={2022},
      eprint={2103.00683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.00683}
}

@misc{monopoly_rules,
    author="Hasbro",
    title="MONOPOLY",
    url="https://www.hasbro.com/common/instruct/00009.pdf",
    note="[Online; accesat 05-Mai-2025]"
}

@misc{monopoly_money,
    author="Wikipedia",
    title="Monopoly money",
    url="https://en.wikipedia.org/wiki/Monopoly_money",
    note="[Online; accesat 08-Mai-2025]"
}

@misc{monopoly_game,
    author="Wikipedia",
    title="Monopoly (game)",
    url="https://en.wikipedia.org/wiki/Monopoly_%28game%29",
    note="[Online; accesat 09-Mai-2025]"
}

@article{monopoly_statistics,
  author    = {Paul R. Murrell},
  title     = {The Statistics of Monopoly},
  journal   = {CHANCE},
  volume    = {12},
  number    = {4},
  pages     = {36--40},
  year      = {1999},
  doi       = {10.1080/09332480.1999.10542173}
}

@misc{dice_statistics,
  title     = {Dice Roll Probability: 6 Sided Dice},
  author    = {{Statistics How To}},
  url       = {https://www.statisticshowto.com/probability-and-statistics/probability-main-index/dice-roll-probability-6-sided-dice/},
  note      = "[Online; accesat 11-Mai-2025]"
}

@misc{monopoly_statistic_players,
 author    = {{b2studios}},
 title     = {AI Learns Insane Monopoly Strategies},
 url       = {https://www.youtube.com/watch?v=dkvFcYBznPI},
 year      = {2021},
 month     = {12},
 day       = {21},
 note      = "[Online; accesat 13-Mai-2025]"
}

@misc{monopoly_statistics_positions,
 author    = {Mathium},
 title     = {Monopoly: The Mathematical Secret Behind Winning},
 url       = {https://www.youtube.com/watch?v=8FP8Owdt2WY&t=58s},
 year      = {2021},
 month     = {1},
 note      = "[Online; accesat 14-Mai-2025]"
}

@book{srp_desing_pattern,
    title={Patterns of Enterprise Application Architecture},
    author={Fowler, Martin},
    year={2002},
    publisher={Addison-Wesley},
    isbn={9780321127426},
    address={Boston, MA},
    note={Enterprise-level application of design principles}
}

@book{solid_patterns,
    title={The Practical Guide to Structured Systems Design},
    author={Page-Jones, Meilir},
    year={1988},
    publisher={Prentice Hall},
    isbn={9780136907695},
    edition={2nd},
    address={Englewood Cliffs, NJ},
    note={Foundational work on system design principles}
}

@misc{srp_quote_source,
 author    = {Robert C. Martin},
 title     = {The Single Responsibility Principle},
 journal   = {The Clean Code Blog},
 year      = {2014},
 note      = "[Online; accesat 16-Mai-2025]"
}

@misc{python_org,
 author    = {{Python Software Foundation}},
 title     = {Python},
 url       = {https://www.python.org/},
 note      = "[Online; accesat 30-Mai-2025]"
}

@misc{geeksforgeeks_oops,
 author    = {{GeeksforGeeks}},
 title     = {Python OOPs Concepts},
 url       = {https://www.geeksforgeeks.org/python-oops-concepts/},
 note      = "[Online; accesat 02-Iunie-2025]"
}

@misc{geeksforgeeks_singleton,
 author    = {{GeeksforGeeks}},
 title     = {Singleton Design Pattern},
 url       = {https://www.geeksforgeeks.org/singleton-design-pattern/},
 note      = "[Online; accesat 17-Mai-2025]"
}

@misc{geeksforgeeks_queue,
 author    = {{GeeksforGeeks}},
 title     = {Queue Data Structure},
 url       = {https://www.geeksforgeeks.org/queue-data-structure/},
 note      = "[Online; accesat 18-Mai-2025]"
}

@misc{geeksforgeeks_marl,
 author    = {{GeeksforGeeks}},
 title     = {Multi-Agent Reinforcement Learning in AI},
 url       = {https://www.geeksforgeeks.org/multi-agent-reinforcement-learning-in-ai/},
 note      = "[Online; accesat 19-Mai-2025]"
}

@misc{holborn2022monopoly,
 author    = {Holborn},
 title     = {8 Tips to Win (Almost) Every Game of Monopoly This Christmas},
 url       = {https://holbornassets.com/blog/finance/8-tips-to-win-almost-every-game-of-monopoly-this-christmas/},
 year      = {2022},
 month     = {12},
 day       = {21},
 note      = "[Online; accesat 22-Mai-2025]"
}

@misc{cahn2025monopoly,
 author    = {Lauren Cahn},
 title     = {How to Win Monopoly, According to a Monopoly World Champion},
 url       = {https://www.rd.com/article/how-to-win-monopoly/},
 year      = {2025},
 month     = {4},
 day       = {24},
 note      = "[Online; accesat 23-Mai-2025]"
}

@misc{sklearn_gridsearch,
 author    = {{scikit-learn}},
 title     = {3.2. Tuning the Hyper-Parameters of an Estimator},
 url       = {https://scikit-learn.org/stable/modules/grid_search.html},
 note      = "[Online; accesat 24-Mai-2025]"
}

@misc{wikipedia_roundrobin,
 title     = {Round-robin Tournament},
 author    = {{Wikipedia}},
 url       = {https://en.wikipedia.org/wiki/Round-robin_tournament},
 language  = {english},
 note      = "[Online; accesat 26-Mai-2025]"
}

@article{expert_learning,
title = {Reinforcement learning from expert demonstrations with application to redundant robot control},
journal = {Engineering Applications of Artificial Intelligence},
volume = {119},
pages = {105753},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105753},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622007436},
author = {Jorge Ramirez and Wen Yu},
keywords = {Reinforcement learning, Expert demonstrations, Biased exploration, Robot manipulator},
abstract = {Current methods of reinforcement learning from expert demonstrations require humans to give all possible demonstrations in the learning phase, which is very difficult for continuous or high-dimensional spaces. In this paper, we proposed biased exploration reinforcement learning to avoid the exploration of unnecessary states and actions of the expert demonstrations. We present a convergence analysis of the novel method. This method is applied to learn the control of a redundant robot manipulator with 7-degree-of-freedom. The experimental results demonstrate that the proposed method accelerates the learning phase. The obtained policy can successfully achieve the pretended task.}
}

@article{alphago,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group},
  doi={10.1038/nature16961}
}

@article{shannon1950chess,
 author    = {Claude E. Shannon},
 title     = {XXII. Programming a Computer for Playing Chess},
 journal   = {Philosophical Magazine},
 volume    = {41},
 number    = {314},
 pages     = {256--275},
 year      = {1950},
 month     = {3},
 doi       = {10.1080/14786445008521796},
 publisher = {Taylor \& Francis}
}

@misc{drl_normalization_benefits,
 author    = {Clare Lyle and Zeyu Zheng and Khimya Khetarpal and James Martens and Hado van Hasselt and Razvan Pascanu and Will Dabney},
 title     = {Normalization and Effective Learning Rates in Reinforcement Learning},
 year      = {2024},
 eprint    = {2407.01800v1},
 archivePrefix = {arXiv},
 note      = {License: CC BY 4.0}
}

@misc{python_inheritance,
 author    = {{Python Software Foundation}},
 title     = {9.5. Inheritance},
 url       = {https://docs.python.org/3/tutorial/classes.html#inheritance},
 note      = "[Online; accesat 27-Mai-2025]"
}

@misc{tensorflow,
 author    = {{Google}},
 title     = {TensorFlow},
 url       = {https://www.tensorflow.org/},
 note      = "[Online; accesat 01-Iunie-2025]"
}

@misc{tensorflow_linear,
 author    = {{Google}},
 title     = {tfl.layers.Linear},
 url       = {https://www.tensorflow.org/lattice/api_docs/python/tfl/layers/Linear},
 note      = "[Online; accesat 28-Mai-2025]"
}

@misc{tensorflow_relu,
 author    = {{Google}},
 title     = {tf.keras.layers.ReLU},
 url       = {https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU},
 note      = "[Online; accesat 29-Mai-2025]"
}

@misc{milvus_target_networks,
 author    = {{Milvus}},
 title     = {What Are Target Networks in DQN},
 url       = {https://milvus.io/ai-quick-reference/what-are-target-networks-in-dqn},
 note      = "[Online; accesat 31-Mai-2025]"
}

@misc{lazyprogrammer_replay_buffer,
 author    = {{Lazy Programmer}},
 title     = {What is the Replay Buffer in DQN (Deep Q-Learning)?},
 url       = {https://lazyprogrammer.me/what-is-the-replay-buffer-in-dqn-deep-q-learning/},
 note      = "[Online; accesat 04-Iunie-2025]"
}

@misc{react_dev,
 author    = {{Meta}},
 title     = {React},
 url       = {https://react.dev/},
 note      = "[Online; accesat 03-Iunie-2025]"
}

@misc{mdn_javascript,
 author    = {{Mozilla Developer Network}},
 title     = {JavaScript},
 url       = {https://developer.mozilla.org/en-US/docs/Web/JavaScript},
 note      = "[Online; accesat 06-Iunie-2025]"
}

@misc{bootstrap,
 author    = {{Bootstrap Team}},
 title     = {Bootstrap},
 url       = {https://getbootstrap.com/},
 note      = "[Online; accesat 05-Iunie-2025]"
}

@misc{fastapi,
 author    = {Sebasti√°n Ramirez},
 title     = {FastAPI},
 url       = {https://fastapi.tiangolo.com/},
 note      = "[Online; accesat 07-Iunie-2025]"
}